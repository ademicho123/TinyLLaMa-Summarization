{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Summarization Model Training\n",
    "\n",
    "This notebook demonstrates the process of training a text summarization model using the provided dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "import ijson\n",
    "import json\n",
    "\n",
    "\n",
    "# Add the project root directory to Python path\n",
    "project_root = str(Path.cwd().parent) if 'notebooks' in str(Path.cwd()) else str(Path.cwd())\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# Import custom modules\n",
    "from src.preprocessing import load_data, preprocess_data, split_and_save_data\n",
    "from src.model import initialize_model, train_model, save_model, summarize\n",
    "from src.evaluation import calculate_rouge, calculate_bleu\n",
    "from src.visualizations import plot_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "raw_data_path = r\"C:\\Users\\ELITEBOOK\\OneDrive\\Desktop\\Projects\\TinyLLaMa-Summarization\\data\\raw\\sample.jsonl\"\n",
    "processed_data_dir = \"../data/processed\"\n",
    "\n",
    "# Load and preprocess data\n",
    "print(\"Loading raw data...\")\n",
    "raw_data = load_data(raw_data_path)\n",
    "\n",
    "print(\"Preprocessing data...\")\n",
    "articles, summaries = preprocess_data(raw_data)\n",
    "\n",
    "# Split and save processed data\n",
    "print(\"Splitting and saving processed data...\")\n",
    "split_and_save_data(articles, summaries, output_dir=processed_data_dir)\n",
    "\n",
    "print(f\"Number of articles: {len(articles)}\")\n",
    "print(f\"Sample article length: {len(articles[0])} characters\")\n",
    "print(f\"Sample summary length: {len(summaries[0])} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "print(\"Loading training data...\")\n",
    "with open(os.path.join(processed_data_dir, \"train.json\"), \"r\") as f:\n",
    "    train_data = []\n",
    "    parser = ijson.parse(f)\n",
    "    for prefix, event, value in parser:\n",
    "        if prefix.endswith('.article'):\n",
    "            article = value\n",
    "            highlights_prefix = prefix.replace('.article', '.highlights')\n",
    "            highlights = next((item[2] for item in parser if item[0] == highlights_prefix), None)\n",
    "            if highlights is not None:\n",
    "                train_data.append({'article': article, 'highlights': highlights})\n",
    "    train_data = train_data[:100000]\n",
    "    \n",
    "# Initialize model\n",
    "print(\"Initializing model...\")\n",
    "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "model, tokenizer = initialize_model(model_name)\n",
    "\n",
    "# Train model\n",
    "print(\"Training model...\")\n",
    "training_stats = train_model(model, tokenizer, train_data, epochs=5)\n",
    "\n",
    "# Plot training loss\n",
    "plot_loss(training_stats['losses'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "print(\"Loading test data...\")\n",
    "with open(os.path.join(processed_data_dir, \"test.json\"), \"r\") as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "# Evaluate on sample from test set\n",
    "print(\"\\nEvaluating model on sample test data:\")\n",
    "rouge_scores = []\n",
    "bleu_scores = []\n",
    "\n",
    "for idx, item in enumerate(test_data[:5]):\n",
    "    generated_summary = summarize(model, tokenizer, item['article'])\n",
    "    rouge = calculate_rouge(item['highlights'], generated_summary)\n",
    "    bleu = calculate_bleu(item['highlights'], generated_summary)\n",
    "    \n",
    "    rouge_scores.append(rouge)\n",
    "    bleu_scores.append(bleu)\n",
    "\n",
    "# Results dictionary\n",
    "results = {\n",
    "    'average_scores': {\n",
    "        'rouge1': avg_rouge1,\n",
    "        'rouge2': avg_rouge2,\n",
    "        'rougeL': avg_rougeL,\n",
    "        'bleu': avg_bleu\n",
    "    },\n",
    "    'example_predictions': [\n",
    "        {\n",
    "            'article': item['article'],\n",
    "            'reference_summary': item['highlights'],\n",
    "            'generated_summary': summarizer.summarize(item['article']),\n",
    "        }\n",
    "        for item in test_data[:5]\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results dictionary\n",
    "results = {\n",
    "    'average_scores': {\n",
    "        'rouge1': avg_rouge1,\n",
    "        'rouge2': avg_rouge2,\n",
    "        'rougeL': avg_rougeL,\n",
    "        'bleu': avg_bleu\n",
    "    },\n",
    "    'example_predictions': [\n",
    "        {\n",
    "            'article': item['article'],\n",
    "            'reference_summary': item['summary'],\n",
    "            'generated_summary': summarizer.summarize(item['article']),\n",
    "        }\n",
    "        for item in test_data[:5]\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Save results\n",
    "os.makedirs('../reports', exist_ok=True)\n",
    "with open('../reports/evaluation_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(\"Evaluation results saved to reports/evaluation_results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save model\n",
    "print(\"Saving model...\")\n",
    "save_model(model, tokenizer, \"../models/tiny-llama-model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
